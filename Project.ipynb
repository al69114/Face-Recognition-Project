{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al69114/blank-app/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sphNGlucAYkK",
        "outputId": "48c7127e-ee94-414a-f362-00377418d825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting inference-sdk\n",
            "  Downloading inference_sdk-0.46.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.3.31-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (2.32.3)\n",
            "Collecting dataclasses-json~=0.6.0 (from inference-sdk)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting supervision<=0.30.0,>=0.25.1 (from inference-sdk)\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting aiohttp<=3.10.11,>=3.9.0 (from inference-sdk)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting backoff~=2.2.0 (from inference-sdk)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: py-cpuinfo~=9.0.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (6.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json~=0.6.0->inference-sdk)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json~=0.6.0->inference-sdk)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (2025.1.31)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json~=0.6.0->inference-sdk) (24.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (2.8.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-sdk)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-sdk) (4.13.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<=3.10.11,>=3.9.0->inference-sdk) (0.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (1.17.0)\n",
            "Downloading inference_sdk-0.46.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.3.31-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: yt-dlp, opencv-python, mypy-extensions, marshmallow, backoff, typing-inspect, aiohttp, supervision, dataclasses-json, inference-sdk\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "Successfully installed aiohttp-3.10.11 backoff-2.2.1 dataclasses-json-0.6.7 inference-sdk-0.46.1 marshmallow-3.26.1 mypy-extensions-1.0.0 opencv-python-4.10.0.84 supervision-0.25.1 typing-inspect-0.9.0 yt-dlp-2025.3.31\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python numpy tqdm pillow inference-sdk yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "from PIL import Image\n",
        "import traceback\n",
        "import base64\n",
        "\n",
        "def download_youtube_video(youtube_url, output_path=\"videos\"):\n",
        "    \"\"\"\n",
        "    Downloads a YouTube video using yt_dlp Python package\n",
        "\n",
        "    Args:\n",
        "        youtube_url (str): URL of the YouTube video\n",
        "        output_path (str): Directory to save the video to\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the downloaded video file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create output directory if it doesn't exist\n",
        "        if not os.path.exists(output_path):\n",
        "            os.makedirs(output_path)\n",
        "\n",
        "        # Generate a timestamp for unique filename\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        output_file = os.path.join(output_path, f\"video_{timestamp}.mp4\")\n",
        "\n",
        "        print(f\"Downloading video from: {youtube_url}\")\n",
        "\n",
        "        # Method 1: Try using yt_dlp as a Python package\n",
        "        try:\n",
        "            from yt_dlp import YoutubeDL\n",
        "\n",
        "            ydl_opts = {\n",
        "                'format': 'best[ext=mp4]',\n",
        "                'outtmpl': output_file,\n",
        "                'quiet': False,\n",
        "                'no_warnings': False,\n",
        "                'ignoreerrors': False,\n",
        "            }\n",
        "\n",
        "            with YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([youtube_url])\n",
        "                print(f\"Download complete with yt_dlp: {output_file}\")\n",
        "                return output_file\n",
        "        except ImportError:\n",
        "            print(\"yt_dlp not installed as Python package. Trying pytube...\")\n",
        "\n",
        "            # Method 2: Try using pytube\n",
        "            try:\n",
        "                from pytube import YouTube\n",
        "\n",
        "                yt = YouTube(youtube_url)\n",
        "                video = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "\n",
        "                if video:\n",
        "                    video.download(output_path=output_path, filename=os.path.basename(output_file))\n",
        "                    print(f\"Download complete with pytube: {output_file}\")\n",
        "                    return output_file\n",
        "                else:\n",
        "                    print(\"No suitable video stream found.\")\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"pytube not installed. Trying youtube_dl...\")\n",
        "\n",
        "                # Method 3: Try using youtube_dl\n",
        "                try:\n",
        "                    import youtube_dl\n",
        "\n",
        "                    youtube_dl_opts = {\n",
        "                        'format': 'best[ext=mp4]',\n",
        "                        'outtmpl': output_file,\n",
        "                    }\n",
        "\n",
        "                    with youtube_dl.YoutubeDL(youtube_dl_opts) as ydl:\n",
        "                        ydl.download([youtube_url])\n",
        "                        print(f\"Download complete with youtube_dl: {output_file}\")\n",
        "                        return output_file\n",
        "                except ImportError:\n",
        "                    print(\"No YouTube download packages found.\")\n",
        "                    raise ImportError(\"Please install one of: yt-dlp, pytube, or youtube-dl\")\n",
        "                except Exception as e:\n",
        "                    print(f\"youtube_dl error: {e}\")\n",
        "                    raise\n",
        "            except Exception as e:\n",
        "                print(f\"pytube error: {e}\")\n",
        "                raise\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading video: {e}\")\n",
        "        print(\"\\nPossible solutions:\")\n",
        "        print(\"1. Install yt-dlp: pip install yt-dlp\")\n",
        "        print(\"2. Or install pytube: pip install pytube\")\n",
        "        print(\"3. Or install youtube-dl: pip install youtube-dl\")\n",
        "        print(\"4. Check your internet connection\")\n",
        "        print(\"5. The video might be restricted or unavailable\")\n",
        "        return None\n",
        "\n",
        "class RoboflowFaceDetector:\n",
        "    \"\"\"\n",
        "    Face detection using Roboflow API\n",
        "    \"\"\"\n",
        "    def __init__(self, api_key=\"RA851UccVU1TP3Ln2aDU\", model_id=\"asasa-mqilf/1\"):\n",
        "        self.api_key = api_key\n",
        "        self.model_id = model_id\n",
        "        self.client = None\n",
        "        self.initialized = False\n",
        "        self.face_encodings = []\n",
        "        self.duplicate_count = 0\n",
        "\n",
        "        try:\n",
        "            from inference_sdk import InferenceHTTPClient\n",
        "            self.client = InferenceHTTPClient(\n",
        "                api_url=\"https://serverless.roboflow.com\",\n",
        "                api_key=self.api_key\n",
        "            )\n",
        "            self.initialized = True\n",
        "            print(f\"Roboflow Face Detection API initialized successfully with model {model_id}!\")\n",
        "        except ImportError:\n",
        "            print(\"Error: inference_sdk not installed. Please install with:\")\n",
        "            print(\"pip install inference-sdk\")\n",
        "            print(\"Falling back to OpenCV for face detection.\")\n",
        "            self._initialize_opencv_fallback()\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing Roboflow client: {e}\")\n",
        "            print(\"Falling back to OpenCV for face detection.\")\n",
        "            self._initialize_opencv_fallback()\n",
        "\n",
        "    def _initialize_opencv_fallback(self):\n",
        "        \"\"\"Initialize OpenCV face detectors as fallback\"\"\"\n",
        "        self.opencv_face_detectors = []\n",
        "\n",
        "        # Try to load DNN face detector\n",
        "        try:\n",
        "            face_detector_dir = \"face_detector\"\n",
        "            face_detector_prototxt = os.path.join(face_detector_dir, \"deploy.prototxt\")\n",
        "            face_detector_model = os.path.join(face_detector_dir, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "\n",
        "            if os.path.exists(face_detector_model) and os.path.exists(face_detector_prototxt):\n",
        "                dnn_face_detector = cv2.dnn.readNetFromCaffe(face_detector_prototxt, face_detector_model)\n",
        "                self.opencv_face_detectors.append((\"dnn\", dnn_face_detector))\n",
        "                print(\"Loaded OpenCV DNN face detector\")\n",
        "            else:\n",
        "                print(\"OpenCV DNN face detector files not found.\")\n",
        "                print(\"For better face detection, download these files:\")\n",
        "                print(\"- deploy.prototxt: https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt\")\n",
        "                print(\"- res10_300x300_ssd_iter_140000.caffemodel: https://github.com/opencv/opencv_3rdparty/blob/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "                print(\"Place them in a 'face_detector' directory\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading OpenCV DNN face detector: {e}\")\n",
        "\n",
        "        # Haar Cascade face detector\n",
        "        try:\n",
        "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "            if not face_cascade.empty():\n",
        "                self.opencv_face_detectors.append((\"haar\", face_cascade))\n",
        "                print(\"Loaded Haar Cascade face detector\")\n",
        "            else:\n",
        "                print(\"Failed to load Haar Cascade face detector\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Haar Cascade: {e}\")\n",
        "\n",
        "    def detect_faces(self, frame):\n",
        "        \"\"\"\n",
        "        Detect faces in a frame using Roboflow API\n",
        "\n",
        "        Args:\n",
        "            frame: OpenCV BGR image\n",
        "\n",
        "        Returns:\n",
        "            list: List of (x, y, w, h) tuples for faces\n",
        "        \"\"\"\n",
        "        # Use Roboflow API if available\n",
        "        if self.initialized and self.client:\n",
        "            try:\n",
        "                # Convert OpenCV frame to PIL Image\n",
        "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                pil_img = Image.fromarray(rgb_frame)\n",
        "\n",
        "                # Save to bytes with correct format\n",
        "                img_byte_arr = io.BytesIO()\n",
        "                pil_img.save(img_byte_arr, format='JPEG')\n",
        "                img_byte_arr.seek(0)  # Reset pointer to beginning\n",
        "\n",
        "                # Get predictions by directly passing the image path\n",
        "                # Convert the image bytes to a temporary file\n",
        "                import tempfile\n",
        "                temp_file = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)\n",
        "                temp_file.write(img_byte_arr.getvalue())\n",
        "                temp_file.close()\n",
        "\n",
        "                # Now use the file path with the API\n",
        "                result = self.client.infer(temp_file.name, model_id=self.model_id)\n",
        "\n",
        "                # Clean up the temporary file\n",
        "                os.unlink(temp_file.name)\n",
        "\n",
        "                # Process predictions\n",
        "                faces = []\n",
        "                for prediction in result.get('predictions', []):\n",
        "                    # Extract bounding box\n",
        "                    if 'x' in prediction and 'y' in prediction and 'width' in prediction and 'height' in prediction:\n",
        "                        # Format where x,y is the center\n",
        "                        x = int(prediction['x'] - prediction['width']/2)\n",
        "                        y = int(prediction['y'] - prediction['height']/2)\n",
        "                        w = int(prediction['width'])\n",
        "                        h = int(prediction['height'])\n",
        "                    elif 'bbox' in prediction:\n",
        "                        # Format with bbox object\n",
        "                        bbox = prediction['bbox']\n",
        "                        x = int(bbox.get('x', 0))\n",
        "                        y = int(bbox.get('y', 0))\n",
        "                        w = int(bbox.get('width', 0))\n",
        "                        h = int(bbox.get('height', 0))\n",
        "                    elif all(k in prediction for k in ['x_min', 'y_min', 'x_max', 'y_max']):\n",
        "                        # Format with min/max coordinates\n",
        "                        x = int(prediction['x_min'])\n",
        "                        y = int(prediction['y_min'])\n",
        "                        w = int(prediction['x_max'] - prediction['x_min'])\n",
        "                        h = int(prediction['y_max'] - prediction['y_min'])\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    # Make sure coordinates are positive\n",
        "                    x = max(0, x)\n",
        "                    y = max(0, y)\n",
        "\n",
        "                    # Skip if width or height is too small\n",
        "                    if w < 20 or h < 20:\n",
        "                        continue\n",
        "\n",
        "                    faces.append((x, y, w, h))\n",
        "\n",
        "                # If we found faces, return them\n",
        "                if faces:\n",
        "                    return faces\n",
        "            except Exception as e:\n",
        "                print(f\"Error with Roboflow API: {e}\")\n",
        "                traceback.print_exc()\n",
        "                print(\"Falling back to OpenCV detection\")\n",
        "\n",
        "        # Fall back to OpenCV if Roboflow failed or not available\n",
        "        return self._detect_faces_opencv(frame)\n",
        "\n",
        "    def _detect_faces_opencv(self, frame):\n",
        "        \"\"\"Detect faces using OpenCV as fallback\"\"\"\n",
        "        if not hasattr(self, 'opencv_face_detectors'):\n",
        "            return []\n",
        "\n",
        "        height, width = frame.shape[:2]\n",
        "        all_faces = []\n",
        "\n",
        "        for detector_name, detector in self.opencv_face_detectors:\n",
        "            faces = []\n",
        "\n",
        "            if detector_name == \"dnn\":\n",
        "                # DNN-based detection\n",
        "                blob = cv2.dnn.blobFromImage(\n",
        "                    cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
        "                    (104.0, 177.0, 123.0), swapRB=False, crop=False\n",
        "                )\n",
        "                detector.setInput(blob)\n",
        "                detections = detector.forward()\n",
        "\n",
        "                for i in range(detections.shape[2]):\n",
        "                    confidence = detections[0, 0, i, 2]\n",
        "                    if confidence > 0.5:\n",
        "                        box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
        "                        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "                        # Ensure coordinates are within frame\n",
        "                        startX, startY = max(0, startX), max(0, startY)\n",
        "                        endX, endY = min(width, endX), min(height, endY)\n",
        "\n",
        "                        w = endX - startX\n",
        "                        h = endY - startY\n",
        "\n",
        "                        # Skip very small faces\n",
        "                        if w < 30 or h < 30:\n",
        "                            continue\n",
        "\n",
        "                        faces.append((startX, startY, w, h))\n",
        "            else:\n",
        "                # Haar Cascade detection\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                detected = detector.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
        "                faces.extend([(x, y, w, h) for (x, y, w, h) in detected])\n",
        "\n",
        "            all_faces.extend(faces)\n",
        "\n",
        "        # Remove duplicates using non-maximum suppression\n",
        "        if len(all_faces) > 1:\n",
        "            # Convert to format for NMS\n",
        "            boxes = [[x, y, x+w, y+h] for (x, y, w, h) in all_faces]\n",
        "            scores = [1.0] * len(boxes)  # Assign equal confidence\n",
        "\n",
        "            # Apply NMS\n",
        "            indices = cv2.dnn.NMSBoxes(boxes, scores, 0.3, 0.3)\n",
        "\n",
        "            # Extract the filtered faces\n",
        "            filtered_faces = []\n",
        "            for i in indices:\n",
        "                if isinstance(i, list):  # OpenCV 3.x returns nested indices\n",
        "                    i = i[0]\n",
        "                x, y, w, h = all_faces[i]\n",
        "                filtered_faces.append((x, y, w, h))\n",
        "\n",
        "            return filtered_faces\n",
        "\n",
        "        return all_faces\n",
        "\n",
        "    def is_duplicate(self, face_img, similarity_threshold=0.75):\n",
        "        \"\"\"\n",
        "        Check if a face is a duplicate using feature-based comparison\n",
        "\n",
        "        Args:\n",
        "            face_img: Face image\n",
        "            similarity_threshold: Threshold for duplicate detection\n",
        "\n",
        "        Returns:\n",
        "            bool: True if duplicate, False if unique\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Extract the upper part of the face (less affected by expressions)\n",
        "            h, w = gray.shape\n",
        "            upper_face = gray[:int(h*0.6), :]\n",
        "\n",
        "            # Resize for consistent comparison\n",
        "            upper_face = cv2.resize(upper_face, (64, 64))\n",
        "\n",
        "            # 1. Compute histogram features\n",
        "            hist = cv2.calcHist([upper_face], [0], None, [64], [0, 256])\n",
        "            cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "            hist_features = hist.flatten()\n",
        "\n",
        "            # 2. Compute edge features (less affected by lighting)\n",
        "            sobelx = cv2.Sobel(upper_face, cv2.CV_64F, 1, 0, ksize=3)\n",
        "            sobely = cv2.Sobel(upper_face, cv2.CV_64F, 0, 1, ksize=3)\n",
        "            magnitude = cv2.magnitude(sobelx, sobely)\n",
        "            edge_mask = (magnitude > magnitude.mean()).astype(np.uint8)\n",
        "\n",
        "            # Combine features\n",
        "            encoding = np.concatenate([hist_features, edge_mask.flatten()])\n",
        "\n",
        "            # Check against existing encodings\n",
        "            for existing_encoding in self.face_encodings:\n",
        "                # Calculate similarity for histogram part\n",
        "                hist_similarity = cv2.compareHist(\n",
        "                    existing_encoding[:64].reshape(-1, 1),\n",
        "                    hist_features.reshape(-1, 1),\n",
        "                    cv2.HISTCMP_CORREL\n",
        "                )\n",
        "\n",
        "                # Calculate similarity for edge part (Hamming distance)\n",
        "                hamming_distance = np.count_nonzero(existing_encoding[64:] != edge_mask.flatten())\n",
        "                edge_similarity = 1.0 - hamming_distance / len(edge_mask.flatten())\n",
        "\n",
        "                # Combined similarity score\n",
        "                similarity = 0.5 * hist_similarity + 0.5 * edge_similarity\n",
        "\n",
        "                if similarity > similarity_threshold:\n",
        "                    self.duplicate_count += 1\n",
        "                    return True\n",
        "\n",
        "            # If we get here, it's a new face\n",
        "            self.face_encodings.append(encoding)\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in duplicate detection: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_duplicate_count(self):\n",
        "        \"\"\"Get the number of duplicates detected\"\"\"\n",
        "        return self.duplicate_count\n",
        "\n",
        "def enhance_face_image(face_img):\n",
        "    \"\"\"\n",
        "    Enhance a face image for better quality\n",
        "\n",
        "    Args:\n",
        "        face_img: Input face image\n",
        "\n",
        "    Returns:\n",
        "        Enhanced face image\n",
        "    \"\"\"\n",
        "    if face_img is None or face_img.size == 0:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Resize for consistency if too small\n",
        "        if face_img.shape[0] < 150 or face_img.shape[1] < 150:\n",
        "            scale = max(150 / face_img.shape[0], 150 / face_img.shape[1])\n",
        "            new_size = (int(face_img.shape[1] * scale), int(face_img.shape[0] * scale))\n",
        "            face_img = cv2.resize(face_img, new_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # Create a copy for processing\n",
        "        enhanced = face_img.copy()\n",
        "\n",
        "        # Convert to LAB color space for better contrast adjustment\n",
        "        lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "\n",
        "        # Apply CLAHE to the L channel\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        cl = clahe.apply(l)\n",
        "\n",
        "        # Merge back the channels\n",
        "        enhanced_lab = cv2.merge((cl, a, b))\n",
        "        enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # Apply slight sharpening\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                          [-1, 9, -1],\n",
        "                          [-1, -1, -1]])\n",
        "        enhanced = cv2.filter2D(enhanced, -1, kernel)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error enhancing face: {e}\")\n",
        "        return face_img  # Return original if enhancement fails\n",
        "\n",
        "def assess_face_quality(face_img, min_size=(50, 50)):\n",
        "    \"\"\"\n",
        "    Assess the quality of a face image\n",
        "\n",
        "    Args:\n",
        "        face_img: Input face image\n",
        "        min_size: Minimum acceptable size for a face\n",
        "\n",
        "    Returns:\n",
        "        tuple: (quality_score, reason)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if face_img is None or face_img.size == 0:\n",
        "            return 0.0, \"Empty image\"\n",
        "\n",
        "        # Check face size\n",
        "        h, w = face_img.shape[:2]\n",
        "        if h < min_size[0] or w < min_size[1]:\n",
        "            return 0.0, \"Too small\"\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Check for blur using Laplacian variance\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        if laplacian_var < 100:\n",
        "            return 0.0, \"Too blurry\"\n",
        "\n",
        "        # Check brightness\n",
        "        brightness = np.mean(gray)\n",
        "        if brightness < 40 or brightness > 215:\n",
        "            return 0.0, \"Poor lighting\"\n",
        "\n",
        "        # Check for contrast\n",
        "        contrast = gray.std()\n",
        "        if contrast < 20:\n",
        "            return 0.0, \"Low contrast\"\n",
        "\n",
        "        # Calculate quality score\n",
        "        blur_score = min(laplacian_var / 500, 1.0)\n",
        "        brightness_score = 1.0 - abs((brightness - 127.5) / 127.5)\n",
        "        contrast_score = min(contrast / 80, 1.0)\n",
        "\n",
        "        # Combine scores\n",
        "        quality_score = (0.5 * blur_score + 0.25 * brightness_score + 0.25 * contrast_score)\n",
        "\n",
        "        return quality_score, \"Pass\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error assessing face quality: {e}\")\n",
        "        return 0.0, str(e)\n",
        "\n",
        "def extract_faces_from_video(video_path, output_dir=\"faces\", frame_skip=30, similarity_threshold=0.75,\n",
        "                           quality_threshold=0.5, max_faces=None, api_key=\"RA851UccVU1TP3Ln2aDU\", model_id=\"asasa-mqilf/1\"):\n",
        "    \"\"\"\n",
        "    Extract unique faces from a video using Roboflow face detection\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to the video file\n",
        "        output_dir: Directory to save faces\n",
        "        frame_skip: Number of frames to skip between processing\n",
        "        similarity_threshold: Threshold for considering faces as duplicates\n",
        "        quality_threshold: Minimum quality score for faces\n",
        "        max_faces: Maximum number of faces to extract\n",
        "        api_key: Roboflow API key\n",
        "        model_id: Roboflow model ID\n",
        "\n",
        "    Returns:\n",
        "        dict: Statistics about the extraction process\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create output directory\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "            print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "        # Initialize counters\n",
        "        frame_count = 0\n",
        "        processed_frames = 0\n",
        "        face_count = 0\n",
        "\n",
        "        # Initialize the face detector\n",
        "        face_detector = RoboflowFaceDetector(api_key=api_key, model_id=model_id)\n",
        "\n",
        "        # Open the video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            return None\n",
        "\n",
        "        # Get video information\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        duration = total_frames / fps if fps > 0 else 0\n",
        "\n",
        "        print(f\"\\nProcessing video: {video_path}\")\n",
        "        print(f\"Total frames: {total_frames}\")\n",
        "        print(f\"FPS: {fps}\")\n",
        "        print(f\"Duration: {duration:.2f} seconds\")\n",
        "        print(f\"Frame interval: {frame_skip}\")\n",
        "\n",
        "        # Setup progress bar\n",
        "        pbar = tqdm(total=total_frames, desc=\"Processing\", unit=\"frames\")\n",
        "\n",
        "        # Get base video name for saving files\n",
        "        video_base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "        # For debugging\n",
        "        save_debug_frames = True\n",
        "        debug_dir = os.path.join(output_dir, \"debug\")\n",
        "        if save_debug_frames and not os.path.exists(debug_dir):\n",
        "            os.makedirs(debug_dir)\n",
        "\n",
        "        # Start processing\n",
        "        processing_start = time.time()\n",
        "        last_debug_saved = 0  # To track when we last saved a debug frame\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "            # Only process every Nth frame\n",
        "            if frame_count % frame_skip != 0:\n",
        "                continue\n",
        "\n",
        "            processed_frames += 1\n",
        "\n",
        "            # Get frame dimensions\n",
        "            height, width = frame.shape[:2]\n",
        "\n",
        "            # Debug image for visualization\n",
        "            debug_image = None\n",
        "            if save_debug_frames and (processed_frames - last_debug_saved >= 30 or processed_frames <= 2):\n",
        "                debug_image = frame.copy()\n",
        "                last_debug_saved = processed_frames\n",
        "\n",
        "            # Detect faces in frame using Roboflow\n",
        "            try:\n",
        "                faces = face_detector.detect_faces(frame)\n",
        "\n",
        "                # Process each detected face\n",
        "                for face_id, (x, y, w, h) in enumerate(faces):\n",
        "                    try:\n",
        "                        # Add margin around face for better results\n",
        "                        margin_x = int(w * 0.2)\n",
        "                        margin_y = int(h * 0.2)\n",
        "                        top_margin = int(h * 0.3)  # Extra margin for forehead\n",
        "\n",
        "                        # Calculate face region with margins\n",
        "                        x1 = max(0, x - margin_x)\n",
        "                        y1 = max(0, y - top_margin)\n",
        "                        x2 = min(width, x + w + margin_x)\n",
        "                        y2 = min(height, y + h + margin_y)\n",
        "\n",
        "                        # Extract face\n",
        "                        face_img = frame[y1:y2, x1:x2]\n",
        "\n",
        "                        # Skip empty or tiny faces\n",
        "                        if face_img is None or face_img.size == 0 or face_img.shape[0] < 20 or face_img.shape[1] < 20:\n",
        "                            continue\n",
        "\n",
        "                        # Assess face quality\n",
        "                        quality_score, reason = assess_face_quality(face_img)\n",
        "\n",
        "                        # Skip low quality faces\n",
        "                        if quality_score < quality_threshold:\n",
        "                            if debug_image is not None:\n",
        "                                cv2.rectangle(debug_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                                cv2.putText(debug_image, f\"Low quality: {reason}\", (x1, y1-10),\n",
        "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "                            continue\n",
        "\n",
        "                        # Check if this is a duplicate face\n",
        "                        if face_detector.is_duplicate(face_img, similarity_threshold):\n",
        "                            # Draw red box for duplicates in debug image\n",
        "                            if debug_image is not None:\n",
        "                                cv2.rectangle(debug_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                                cv2.putText(debug_image, \"Duplicate\", (x1, y1-10),\n",
        "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "                            continue\n",
        "\n",
        "                        # If we got here, it's a unique face - enhance and save it\n",
        "                        enhanced_face = enhance_face_image(face_img)\n",
        "                        if enhanced_face is None:\n",
        "                            continue\n",
        "\n",
        "                        # Save the face\n",
        "                        face_count += 1\n",
        "                        face_filename = f\"{video_base_name}_face_{face_count:04d}_{quality_score:.2f}.jpg\"\n",
        "                        cv2.imwrite(os.path.join(output_dir, face_filename), enhanced_face)\n",
        "\n",
        "                        # Draw green box for saved faces in debug image\n",
        "                        if debug_image is not None:\n",
        "                            cv2.rectangle(debug_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                            cv2.putText(debug_image, f\"#{face_count}\", (x1, y1-10),\n",
        "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "                        # Update progress bar\n",
        "                        pbar.set_description(f\"Found: {face_count} faces (filtered: {face_detector.get_duplicate_count()})\")\n",
        "\n",
        "                        # Check if we've reached the maximum number of faces\n",
        "                        if max_faces and face_count >= max_faces:\n",
        "                            print(f\"\\nReached maximum number of faces ({max_faces})\")\n",
        "                            break\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing face {face_id}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                # Save debug image if needed\n",
        "                if debug_image is not None and save_debug_frames:\n",
        "                    debug_filename = f\"{video_base_name}_debug_{processed_frames:04d}.jpg\"\n",
        "                    cv2.imwrite(os.path.join(debug_dir, debug_filename), debug_image)\n",
        "\n",
        "                # Check if we've reached the maximum number of faces\n",
        "                if max_faces and face_count >= max_faces:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing frame {frame_count}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Clean up\n",
        "        cap.release()\n",
        "        pbar.close()\n",
        "\n",
        "        # Calculate processing statistics\n",
        "        processing_time = time.time() - processing_start\n",
        "        processing_fps = processed_frames / processing_time if processing_time > 0 else 0\n",
        "\n",
        "        # Create a montage of all unique faces for quick review\n",
        "        try:\n",
        "            # We don't have a direct way to access the original face images from the detector,\n",
        "            # so we'll read back the saved faces to create the montage\n",
        "            face_files = [f for f in os.listdir(output_dir) if f.startswith(video_base_name) and \"debug\" not in f]\n",
        "\n",
        "            if face_files:\n",
        "                # Sort files numerically\n",
        "                face_files.sort(key=lambda x: int(x.split(\"_face_\")[1].split(\"_\")[0]))\n",
        "\n",
        "                # Read files into memory\n",
        "                faces = []\n",
        "                for file in face_files:\n",
        "                    try:\n",
        "                        face = cv2.imread(os.path.join(output_dir, file))\n",
        "                        if face is not None:\n",
        "                            faces.append(face)\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                if faces:\n",
        "                    # Resize all to same dimensions\n",
        "                    target_size = (150, 150)\n",
        "                    resized_faces = [cv2.resize(face, target_size) for face in faces]\n",
        "\n",
        "                    # Determine layout for montage\n",
        "                    n_faces = len(resized_faces)\n",
        "                    cols = min(5, n_faces)  # Max 5 faces per row\n",
        "                    rows = (n_faces + cols - 1) // cols\n",
        "\n",
        "                    # Create blank montage\n",
        "                    montage = np.zeros((rows * target_size[1], cols * target_size[0], 3), dtype=np.uint8)\n",
        "\n",
        "                    # Fill montage with faces\n",
        "                    for i, face in enumerate(resized_faces):\n",
        "                        if i >= rows * cols:\n",
        "                            break\n",
        "\n",
        "                        row = i // cols\n",
        "                        col = i % cols\n",
        "\n",
        "                        y_start = row * target_size[1]\n",
        "                        y_end = y_start + target_size[1]\n",
        "                        x_start = col * target_size[0]\n",
        "                        x_end = x_start + target_size[0]\n",
        "\n",
        "                        montage[y_start:y_end, x_start:x_end] = face\n",
        "\n",
        "                    # Save montage\n",
        "                    montage_path = os.path.join(output_dir, f\"{video_base_name}_unique_faces_montage.jpg\")\n",
        "                    cv2.imwrite(montage_path, montage)\n",
        "                    print(f\"Created montage of all unique faces: {montage_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating faces montage: {e}\")\n",
        "\n",
        "        # Print summary\n",
        "        print(\"\\n====== Face Extraction Complete ======\")\n",
        "        print(f\"Video: {video_path}\")\n",
        "        print(f\"Total frames: {total_frames}\")\n",
        "        print(f\"Processed frames: {processed_frames}\")\n",
        "        print(f\"Unique faces found: {face_count}\")\n",
        "        print(f\"Duplicates filtered: {face_detector.get_duplicate_count()}\")\n",
        "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
        "        print(f\"Processing speed: {processing_fps:.2f} frames/second\")\n",
        "        print(f\"Faces saved to: {output_dir}\")\n",
        "\n",
        "        if face_count == 0:\n",
        "            print(\"\\nNo faces were detected. Possible reasons:\")\n",
        "            print(\"1. The video may not contain clear faces\")\n",
        "            print(f\"2. The quality threshold may be too high (currently {quality_threshold})\")\n",
        "            print(f\"3. The frame interval may be too large (currently every {frame_skip} frames)\")\n",
        "\n",
        "        return {\n",
        "            \"total_frames\": total_frames,\n",
        "            \"processed_frames\": processed_frames,\n",
        "            \"unique_faces\": face_count,\n",
        "            \"duplicates_filtered\": face_detector.get_duplicate_count(),\n",
        "            \"processing_time\": processing_time,\n",
        "            \"output_dir\": output_dir\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in extract_faces_from_video: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"YouTube Face Extractor with Roboflow API\")\n",
        "        print(\"=======================================\")\n",
        "\n",
        "        # Get YouTube URL from user\n",
        "        youtube_url = input(\"Enter YouTube video URL: \")\n",
        "\n",
        "        # Other parameters\n",
        "        frame_skip = int(input(\"Enter frame skip rate (default: 30): \") or \"30\")\n",
        "        output_dir = input(\"Enter output directory (default: 'faces'): \") or \"faces\"\n",
        "        max_faces_input = input(\"Maximum number of faces to extract (optional): \")\n",
        "        max_faces = int(max_faces_input) if max_faces_input.strip() else None\n",
        "\n",
        "        # Advanced parameters - with defaults that work well\n",
        "        print(\"\\nAdvanced parameters (press Enter to use defaults):\")\n",
        "        similarity_threshold = float(input(\"Similarity threshold (0.5-0.9, default: 0.75): \") or \"0.75\")\n",
        "        similarity_threshold = max(0.5, min(0.9, similarity_threshold))\n",
        "\n",
        "        quality_threshold = float(input(\"Quality threshold (0.3-0.8, default: 0.5): \") or \"0.5\")\n",
        "        quality_threshold = max(0.3, min(0.8, quality_threshold))\n",
        "\n",
        "        # Roboflow parameters\n",
        "        api_key = input(\"Enter Roboflow API key (press Enter to use default): \") or \"RA851UccVU1TP3Ln2aDU\"\n",
        "        model_id = input(\"Enter Roboflow model ID (press Enter to use default): \") or \"asasa-mqilf/1\"\n",
        "\n",
        "        # Download the video\n",
        "        print(\"\\nDownloading video...\")\n",
        "        video_path = download_youtube_video(youtube_url)\n",
        "\n",
        "        if video_path and os.path.exists(video_path):\n",
        "            print(f\"Video successfully downloaded to {video_path}\")\n",
        "\n",
        "            # Extract faces\n",
        "            print(\"\\nStarting face extraction with Roboflow...\")\n",
        "            result = extract_faces_from_video(\n",
        "                video_path,\n",
        "                output_dir=output_dir,\n",
        "                frame_skip=frame_skip,\n",
        "                similarity_threshold=similarity_threshold,\n",
        "                quality_threshold=quality_threshold,\n",
        "                max_faces=max_faces,\n",
        "                api_key=api_key,\n",
        "                model_id=model_id\n",
        "            )\n",
        "\n",
        "            # Clean up downloaded video\n",
        "            try:\n",
        "                os.remove(video_path)\n",
        "                print(f\"Temporary video file removed\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not remove temporary file: {e}\")\n",
        "\n",
        "            # Show final results\n",
        "            if result and result[\"unique_faces\"] > 0:\n",
        "                print(\"\\nExtraction complete! To see your faces, check the directory:\")\n",
        "                print(f\"  {os.path.abspath(output_dir)}\")\n",
        "                print(f\"\\nA montage of all unique faces has been created at:\")\n",
        "                print(f\"  {os.path.abspath(os.path.join(output_dir, os.path.basename(video_path).split('.')[0] + '_unique_faces_montage.jpg'))}\")\n",
        "                print(\"\\nFor the best results, make sure you have the inference SDK installed:\")\n",
        "                print(\"  pip install inference-sdk\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nFailed to download video. Please check the URL or your internet connection.\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        print(\"Please check your dependencies and try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYORwLDQijYx",
        "outputId": "7f907ed6-2369-46e5-b090-9facfb189352"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YouTube Face Extractor with Roboflow API\n",
            "=======================================\n",
            "Enter YouTube video URL: https://www.youtube.com/shorts/-sP9jqNNvGU\n",
            "Enter frame skip rate (default: 30): \n",
            "Enter output directory (default: 'faces'): \n",
            "Maximum number of faces to extract (optional): \n",
            "\n",
            "Advanced parameters (press Enter to use defaults):\n",
            "Similarity threshold (0.5-0.9, default: 0.75): \n",
            "Quality threshold (0.3-0.8, default: 0.5): \n",
            "Enter Roboflow API key (press Enter to use default): \n",
            "Enter Roboflow model ID (press Enter to use default): \n",
            "\n",
            "Downloading video...\n",
            "Downloading video from: https://www.youtube.com/shorts/-sP9jqNNvGU\n",
            "[youtube] Extracting URL: https://www.youtube.com/shorts/-sP9jqNNvGU\n",
            "[youtube] -sP9jqNNvGU: Downloading webpage\n",
            "[youtube] -sP9jqNNvGU: Downloading tv client config\n",
            "[youtube] -sP9jqNNvGU: Downloading player 9599b765-main\n",
            "[youtube] -sP9jqNNvGU: Downloading tv player API JSON\n",
            "[youtube] -sP9jqNNvGU: Downloading ios player API JSON\n",
            "[youtube] -sP9jqNNvGU: Downloading m3u8 information\n",
            "[info] -sP9jqNNvGU: Downloading 1 format(s): 18\n",
            "[download] Destination: videos/video_20250414_021353.mp4\n",
            "[download] 100% of    3.99MiB in 00:00:00 at 9.69MiB/s   \n",
            "Download complete with yt_dlp: videos/video_20250414_021353.mp4\n",
            "Video successfully downloaded to videos/video_20250414_021353.mp4\n",
            "\n",
            "Starting face extraction with Roboflow...\n",
            "Roboflow Face Detection API initialized successfully with model asasa-mqilf/1!\n",
            "\n",
            "Processing video: videos/video_20250414_021353.mp4\n",
            "Total frames: 1677\n",
            "FPS: 30\n",
            "Duration: 55.90 seconds\n",
            "Frame interval: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found: 1 faces (filtered: 0): 100%|██████████| 1677/1677 [00:20<00:00, 82.76frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created montage of all unique faces: faces/video_20250414_021353_unique_faces_montage.jpg\n",
            "\n",
            "====== Face Extraction Complete ======\n",
            "Video: videos/video_20250414_021353.mp4\n",
            "Total frames: 1677\n",
            "Processed frames: 55\n",
            "Unique faces found: 1\n",
            "Duplicates filtered: 0\n",
            "Processing time: 20.26 seconds\n",
            "Processing speed: 2.71 frames/second\n",
            "Faces saved to: faces\n",
            "Temporary video file removed\n",
            "\n",
            "Extraction complete! To see your faces, check the directory:\n",
            "  /content/faces\n",
            "\n",
            "A montage of all unique faces has been created at:\n",
            "  /content/faces/video_20250414_021353_unique_faces_montage.jpg\n",
            "\n",
            "For the best results, make sure you have the inference SDK installed:\n",
            "  pip install inference-sdk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB1q1tC6wNvr",
        "outputId": "10984885-0165-443c-8e1a-ac90951b10c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: inference-sdk in /usr/local/lib/python3.11/dist-packages (0.46.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (2.32.3)\n",
            "Requirement already satisfied: dataclasses-json~=0.6.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (0.6.7)\n",
            "Requirement already satisfied: opencv-python<=4.10.0.84,>=4.8.1.78 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (4.10.0.84)\n",
            "Requirement already satisfied: pillow<12.0,>=11.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (11.1.0)\n",
            "Requirement already satisfied: supervision<=0.30.0,>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (0.25.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (2.0.2)\n",
            "Requirement already satisfied: aiohttp<=3.10.11,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (3.10.11)\n",
            "Requirement already satisfied: backoff~=2.2.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (2.2.1)\n",
            "Requirement already satisfied: py-cpuinfo~=9.0.0 in /usr/local/lib/python3.11/dist-packages (from inference-sdk) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (6.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json~=0.6.0->inference-sdk) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json~=0.6.0->inference-sdk) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.0->inference-sdk) (2025.1.31)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision<=0.30.0,>=0.25.1->inference-sdk) (4.67.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json~=0.6.0->inference-sdk) (24.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (2.8.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-sdk) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-sdk) (4.13.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<=3.10.11,>=3.9.0->inference-sdk) (0.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-sdk) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade inference-sdk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW6Bt1DytC7P",
        "outputId": "5fd6d6a2-58de-4cbc-c918-ecb0fdb4d86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in 'faces' deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def delete_files_in_directory(directory=\"faces\"):\n",
        "    \"\"\"Deletes all files within the specified directory.\"\"\"\n",
        "    try:\n",
        "        for filename in os.listdir(directory):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "        print(f\"Files in '{directory}' deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Directory '{directory}' not found.\")\n",
        "\n",
        "# Example usage:\n",
        "delete_files_in_directory()  # Deletes files in \"extracted_frames\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2WJNta4ZOtRc+CU52THGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}